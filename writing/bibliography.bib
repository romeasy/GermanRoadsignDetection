@inproceedings{cDBNs,
  author = {Lee, Honglak and Grosse, Roger and Ranganath, Rajesh and Ng, Andrew Y.},
  title = {Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations},
  booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
  series = {ICML '09},
  year = {2009},
  isbn = {978-1-60558-516-1},
  pages = {609--616},
  numpages = {8},
  url = {\url{http://doi.acm.org/10.1145/1553374.1553453}},
  doi = {10.1145/1553374.1553453},
  acmid = {1553453},
  publisher = {ACM},
  address = {New York, NY, USA},
}

@inproceedings{theano,
     author = {Bergstra, James and Breuleux, Olivier and Bastien, Fr{\'{e}}d{\'{e}}ric and Lamblin, Pascal and Pascanu, Razvan and Desjardins, Guillaume and Turian, Joseph and Warde-Farley, David and Bengio, Yoshua},
      month = jun,
      title = {Theano: a {CPU} and {GPU} Math Expression Compiler},
  booktitle = {Proceedings of the Python for Scientific Computing Conference ({SciPy})},
       year = {2010},
   location = {Austin, TX},
       note = {Oral Presentation},
   abstract = {Theano is a compiler for mathematical expressions in Python that combines the convenience of NumPy’s syntax with the speed of optimized native machine language. The user composes mathematical expressions in a high-level description that mimics NumPy’s syntax and semantics, while being statically typed and
functional (as opposed to imperative). These expressions allow Theano to provide symbolic differentiation. Before performing computation, Theano optimizes the choice of expressions, translates
them into C++ (or CUDA for GPU), compiles them into dynamically loaded Python modules, all automatically. Common machine learning algorithms implemented with Theano are from 1.6× to 7.5× faster than competitive alternatives (including those implemented with C/C++, NumPy/SciPy and MATLAB) when compiled for the
CPU and between 6.5× and 44× faster when compiled for the GPU. This paper illustrates how to use Theano, outlines the scope of the compiler, provides benchmarks on both CPU and GPU processors, and explains its overall design.}
}

@book{perceptron,
  title={The perceptron, a perceiving and recognizing automaton Project Para},
  author={Rosenblatt, Frank},
  year={1957},
  publisher={Cornell Aeronautical Laboratory}
}

@inproceedings{nlpANN,
  title={A unified architecture for natural language processing: Deep neural networks with multitask learning},
  author={Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={160--167},
  year={2008},
  organization={ACM}
}

@article{roboticsANN,
  title={An efficient neural network approach to dynamic robot motion planning},
  author={Yang, Simon X and Meng, Max},
  journal={Neural Networks},
  volume={13},
  number={2},
  pages={143--148},
  year={2000},
  publisher={Elsevier}
}

@inproceedings{visionANN,
  title={Learning deep features for scene recognition using places database},
  author={Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
  booktitle={Advances in neural information processing systems},
  pages={487--495},
  year={2014}
}

@article{backprop,
  title={Beyond regression: New tools for prediction and analysis in the behavioral sciences},
  author={Werbos, Paul},
  year={1974}
}

@techreport{xorProblem,
  title={Learning internal representations by error propagation},
  author={Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J},
  year={1985},
  institution={DTIC Document}
}

@article{cnnOriginal,
  title={Gradient-based learning applied to document recognition},
  author={LeCun, Yann and Bottou, L{\'e}on and Bengio, Yoshua and Haffner, Patrick},
  journal={Proceedings of the IEEE},
  volume={86},
  number={11},
  pages={2278--2324},
  year={1998},
  publisher={IEEE}
}

@book{mackayLearning,
  title={Information theory, inference and learning algorithms},
  author={MacKay, David JC},
  year={2003},
  publisher={Cambridge university press}
}

@book{elementsStats,
  title={The elements of statistical learning},
  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},
  volume={1},
  year={2001},
  publisher={Springer series in statistics Springer, Berlin}
}

@book{bishop,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, C.M.},
  isbn={9780387310732},
  lccn={2006922522},
  series={Information Science and Statistics},
  url={https://books.google.de/books?id=kTNoQgAACAAJ},
  year={2006},
  publisher={Springer}
}

@misc{overviewGD,
  title = {An overview of gradient descent optimization algorithms},
  author={Sebastian Ruder},
  howpublished = {\url{http://sebastianruder.com/optimizing-gradient-descent/index.html}},
  note = {Accessed: 2016-06-02}
}

@misc{lecunConvADF, 
  author={LeCun, Yann},
  title={L'apprentissage profond: une révolution en intelligence artificielle},
  howpublished="\url{http://www.college-de-france.fr/site/yann-lecun/course-2016-02-26-11h00.htm}",
  year={2015}, 
  note = {Accessed: 2016-06-26}
}



@article{cudnn,
  title={cudnn: Efficient primitives for deep learning},
  author={Chetlur, Sharan and Woolley, Cliff and Vandermersch, Philippe and Cohen, Jonathan and Tran, John and Catanzaro, Bryan and Shelhamer, Evan},
  journal={arXiv preprint arXiv:1410.0759},
  year={2014}
}

@article{inefficientBatch,
  title={The general inefficiency of batch training for gradient descent learning},
  author={Wilson, D Randall and Martinez, Tony R},
  journal={Neural Networks},
  volume={16},
  number={10},
  pages={1429--1451},
  year={2003},
  publisher={Elsevier}
}

@article{efficientBatch,
  title={Representation theory and invariant neural networks},
  author={Wood, Jeffrey and Shawe-Taylor, John},
  journal={Discrete applied mathematics},
  volume={69},
  number={1},
  pages={33--60},
  year={1996},
  publisher={Elsevier}
}

@inproceedings{sermanet2011traffic,
  title={Traffic sign recognition with multi-scale convolutional networks},
  author={Sermanet, Pierre and LeCun, Yann},
  booktitle={Neural Networks (IJCNN), The 2011 International Joint Conference on},
  pages={2809--2813},
  year={2011},
  organization={IEEE}
}


@misc{MNIST,
  title={The MNIST database of handwritten digits},
  author={LeCun, Yann and Cortes, Corinna and Burges, Christopher JC},
  year={1998}
}

@inproceedings{GTSRB,
  title={The German traffic sign recognition benchmark: a multi-class classification competition},
  author={Stallkamp, Johannes and Schlipsing, Marc and Salmen, Jan and Igel, Christian},
  booktitle={Neural Networks (IJCNN), The 2011 International Joint Conference on},
  pages={1453--1460},
  year={2011},
  organization={IEEE}
}

@article{ILSVRC15,
Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
Title = {{ImageNet Large Scale Visual Recognition Challenge}},
Year = {2015},
journal   = {International Journal of Computer Vision (IJCV)},
doi = {10.1007/s11263-015-0816-y},
volume={115},
number={3},
pages={211-252}
}




@incollection{efficientBackProp,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@misc{hintonCourseANN,
  title={Neural Networks for Machine Learning},
  author={Hinton, Geoffrey E},
  institution={University of Toronto},
  howpublished="\url{https://www.coursera.org/learn/neural-networks}",
  year={2014},
  note={Accessed: 2016-07-22}
}

@misc{cvTipps,
  title={Cross-validation: evaluating estimator performance},
  author={Scikit-learn developers},
  howpublished="\url{http://scikit-learn.org/stable/modules/cross_validation.html}",
  year={2014},
  note={Accessed: 2016-07-22}
}



@article{abadi2015tensorflow,
  title={TensorFlow: Large-scale machine learning on heterogeneous systems, 2015},
  author={Abadi, Mart{\i}n and Agarwal, Ashish and Barham, Paul and Brevdo, Eugene and Chen, Zhifeng and Citro, Craig and Corrado, Greg S and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and others},
  journal={Software available from tensorflow. org},
  volume={1},
  year={2015}
}

@misc{deepNetworkImage, 
  author={Mayo, Matthew},
  title={Top 5 arXiv Deep Learning Papers, Explained},
  howpublished="\url{http://www.kdnuggets.com/2015/10/top-arxiv-deep-learning-papers-explained.html}",
  year={2015}, 
  note = {Accessed: 2016-07-21}
}



@misc{gridsearchHyperparams,
  author={Brownlee, Jason},
  title={How to Grid Search Hyperparameters for Deep Learning Models in Python With Keras},
  howpublished="\url{http://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras}",
  year={2016},
  note={Accessed: 2016-12-15}
}

@article{shamir2010pattern,
  title={Pattern recognition software and techniques for biological image analysis},
  author={Shamir, Lior and Delaney, John D and Orlov, Nikita and Eckley, D Mark and Goldberg, Ilya G},
  journal={PLoS Comput Biol},
  volume={6},
  number={11},
  pages={e1000974},
  year={2010},
  publisher={Public Library of Science}
}